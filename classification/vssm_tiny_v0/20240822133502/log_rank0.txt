[2024-08-22 13:35:05 vssm_tiny_v0] (main.py 432): INFO Full config saved to /lustre/scratch/client/vinai/users/trangpvh1/repo/vinai_prj/VMamba_Global_local_1/classification/vssm_tiny_v0/20240822133502/config.json
[2024-08-22 13:35:05 vssm_tiny_v0] (main.py 435): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 32
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /lustre/scratch/client/vinai/users/trangpvh1/imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 8
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  MMCKPT: false
  NAME: vssm_tiny_v0
  NUM_CLASSES: 1000
  PRETRAINED: ''
  RESUME: ''
  TYPE: vssm
  VSSM:
    DEPTHS:
    - 2
    - 2
    - 9
    - 2
    DOWNSAMPLE: v1
    EMBED_DIM: 96
    GMLP: false
    IN_CHANS: 3
    MLP_ACT_LAYER: gelu
    MLP_DROP_RATE: 0.0
    MLP_RATIO: 4.0
    NORM_LAYER: ln
    PATCHEMBED: v1
    PATCH_NORM: true
    PATCH_SIZE: 4
    POSEMBED: false
    SSM_ACT_LAYER: silu
    SSM_CONV: 3
    SSM_CONV_BIAS: true
    SSM_DROP_RATE: 0.0
    SSM_DT_RANK: auto
    SSM_D_STATE: 16
    SSM_FORWARDTYPE: v0
    SSM_INIT: v0
    SSM_RANK_RATIO: 2.0
    SSM_RATIO: 2.0
OUTPUT: /lustre/scratch/client/vinai/users/trangpvh1/repo/vinai_prj/VMamba_Global_local_1/classification/vssm_tiny_v0/20240822133502
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: '20240822133502'
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 3.125e-05
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 3.125e-07
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 3.125e-08
  WEIGHT_DECAY: 0.05
TRAINCOST_MODE: false

[2024-08-22 13:35:05 vssm_tiny_v0] (main.py 436): INFO {"cfg": "/lustre/scratch/client/vinai/users/trangpvh1/repo/vinai_prj/VMamba_Global_local_1/classification/configs/vssmab/vmambav0_tiny_224_a0.yaml", "opts": null, "batch_size": 32, "data_path": "/lustre/scratch/client/vinai/users/trangpvh1/imagenet", "zip": false, "cache_mode": "part", "pretrained": null, "resume": null, "accumulation_steps": null, "use_checkpoint": false, "disable_amp": false, "output": "/lustre/scratch/client/vinai/users/trangpvh1/repo/vinai_prj/VMamba_Global_local_1/classification", "tag": "20240822133502", "eval": false, "throughput": false, "fused_layernorm": false, "optim": null, "model_ema": true, "model_ema_decay": 0.9999, "model_ema_force_cpu": false, "memory_limit_rate": -1}
[2024-08-22 13:35:11 vssm_tiny_v0] (main.py 109): INFO Creating model:vssm/vssm_tiny_v0
[2024-08-22 13:35:12 vssm_tiny_v0] (main.py 114): INFO VSSM(
  (patch_embed): Sequential(
    (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
    (1): Permute()
    (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (layers): ModuleList(
    (0): Sequential(
      (blocks): Sequential(
        (0): VSSBlock(
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=96, out_features=384, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
            (out_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=192, out_features=96, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.0)
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=96, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=96,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=96, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
        (1): VSSBlock(
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=96, out_features=384, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
            (out_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=192, out_features=96, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.014285714365541935)
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=96, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=96,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=96, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
      )
      (downsample): PatchMerging2D(
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): Sequential(
      (blocks): Sequential(
        (0): VSSBlock(
          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=192, out_features=768, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
            (out_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=384, out_features=192, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.02857142873108387)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=192, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=192,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=192, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
        (1): VSSBlock(
          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=192, out_features=768, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
            (out_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=384, out_features=192, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.04285714402794838)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=192, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=192,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=192, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
      )
      (downsample): PatchMerging2D(
        (reduction): Linear(in_features=768, out_features=384, bias=False)
        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): Sequential(
      (blocks): Sequential(
        (0): VSSBlock(
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=384, out_features=1536, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            (out_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=768, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.05714285746216774)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=384, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=384,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=384, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
        (1): VSSBlock(
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=384, out_features=1536, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            (out_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=768, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.0714285746216774)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=384, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=384,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=384, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
        (2): VSSBlock(
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=384, out_features=1536, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            (out_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=768, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.08571428805589676)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=384, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=384,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=384, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
        (3): VSSBlock(
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=384, out_features=1536, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            (out_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=768, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.10000000149011612)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=384, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=384,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=384, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
        (4): VSSBlock(
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=384, out_features=1536, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            (out_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=768, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.11428571492433548)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=384, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=384,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=384, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
        (5): VSSBlock(
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=384, out_features=1536, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            (out_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=768, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.12857143580913544)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=384, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=384,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=384, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
        (6): VSSBlock(
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=384, out_features=1536, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            (out_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=768, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.1428571492433548)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=384, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=384,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=384, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
        (7): VSSBlock(
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=384, out_features=1536, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            (out_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=768, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.15714286267757416)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=384, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=384,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=384, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
        (8): VSSBlock(
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=384, out_features=1536, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            (out_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=768, out_features=384, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.17142857611179352)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=384, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=384,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=384, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
      )
      (downsample): PatchMerging2D(
        (reduction): Linear(in_features=1536, out_features=768, bias=False)
        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): Sequential(
      (blocks): Sequential(
        (0): VSSBlock(
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=768, out_features=3072, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536)
            (out_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=1536, out_features=768, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.18571428954601288)
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=768, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=768,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=768, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
        (1): VSSBlock(
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (op): SS2D(
            (in_proj): Linear(in_features=768, out_features=3072, bias=False)
            (act): SiLU()
            (conv2d): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536)
            (out_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (out_proj): Linear(in_features=1536, out_features=768, bias=False)
            (dropout): Identity()
          )
          (drop_path): timm.DropPath(0.20000000298023224)
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): MoE_vmamba(
            (fc1): FMoESSMMLPOpt(
              (gate): CustomNaiveGate_Balance_SMoE(
                (gate): Linear(in_features=768, out_features=16, bias=True)
              )
              (experts): _Expert(
                (htoh4): FMoELinear(num_expert=16, in_features=768,         out_features=48, bias=True, rank=0)
                (h4toh): FMoELinear(num_expert=16, in_features=48,         out_features=768, bias=True, rank=0)
                (activation): GELU(approximate='none')
              )
            )
          )
        )
      )
      (downsample): Identity()
    )
  )
  (classifier): Sequential(
    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (permute): Permute()
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (head): Linear(in_features=768, out_features=1000, bias=True)
  )
)
[2024-08-22 13:35:12 vssm_tiny_v0] (main.py 116): INFO number of params: 31646968
